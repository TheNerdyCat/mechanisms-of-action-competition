{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanisms of Action (MoA) Prediction - 0 Label Classifier\n",
    "## Test\n",
    "\n",
    "In this notebook, we will create a test data prediction pipeline for 0-label records in order to produce a submission file. This prediction pipeline will not end up producing finalised submission files, but will be used to assess the efficacy of our 0-label classifiers, and ultimately tell us where this algorithm belongs in our entire prediction pipeline.\n",
    "\n",
    "## 1.00 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data vis packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Data prep\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modelling packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as k\n",
    "# Key layers\n",
    "from tensorflow.keras.models import load_model\n",
    "# Cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "strategy = tf.distribute.get_strategy()\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')\n",
    "\n",
    "# Data access\n",
    "gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.00 Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory and file paths\n",
    "input_dir                 = '../input/lish-moa/'\n",
    "train_features_path       = os.path.join(input_dir, 'train_features.csv')\n",
    "test_features_path        = os.path.join(input_dir, 'test_features.csv')\n",
    "train_targets_scored_path = os.path.join(input_dir, 'train_targets_scored.csv')\n",
    "sample_submission_path    = os.path.join(input_dir, 'sample_submission.csv')\n",
    "\n",
    "# Read in data\n",
    "train_features       = pd.read_csv(train_features_path)\n",
    "test_features        = pd.read_csv(test_features_path)\n",
    "train_targets_scored = pd.read_csv(train_targets_scored_path)\n",
    "sample_submission    = pd.read_csv(sample_submission_path)\n",
    "\n",
    "del train_features_path, test_features_path, train_targets_scored_path, sample_submission_path\n",
    "\n",
    "print(f'train_features shape: \\t\\t{train_features.shape}')\n",
    "print(f'test_features shape: \\t\\t{test_features.shape}')\n",
    "print(f'train_targets_scored shape: \\t{train_targets_scored.shape}')\n",
    "print(f'sample_submission shape: \\t{sample_submission.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key parameters\n",
    "SCALER_METHOD = RobustScaler()\n",
    "\n",
    "KFOLDS = 10\n",
    "\n",
    "MODEL_TO_USE = 'nn'\n",
    "MODEL_NAME = MODEL_TO_USE + '_0_label_classifier'\n",
    "\n",
    "print(f'Model name: {MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.00 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_target_data(data):\n",
    "    \"\"\"\n",
    "    Transforms the target dataset with multiple labels into \n",
    "    a dataset that has one label (indicating whether there were\n",
    "    0 labels or not)\n",
    "    \"\"\"\n",
    "    # Get number of labels per sig_id\n",
    "    data_transformed = data.drop('sig_id', axis=1).sum(axis=1)\n",
    "    data_transformed = pd.DataFrame(data_transformed).rename(columns={0:'num_labels'})\n",
    "    # Add labels based on whether there are zero labels or not\n",
    "    data_transformed['has_zero_label'] = 0\n",
    "    data_transformed.loc[data_transformed.num_labels == 0, 'has_zero_label'] = 1\n",
    "    # Remove num_labels feature for final target df\n",
    "    data_transformed = data_transformed.drop('num_labels', axis=1)\n",
    "    \n",
    "    return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_feature_set(X_train, X_test, y_train, \n",
    "                          seed,\n",
    "                          num_components,\n",
    "                          verbose=0, \n",
    "                          scaler=SCALER_METHOD\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    Takes in X_train and X_test datasets, and applies feature selection, scaling and pca\n",
    "    depending on arguments. \n",
    "    \n",
    "    Returns X_train and X_test data ready for training/prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_selector = RandomForestClassifier(random_state=seed)\n",
    "    pca = PCA(n_components=num_components, random_state=seed)\n",
    "    \n",
    "    ## DATA PREPARATION ##\n",
    "    \n",
    "    # Drop unique ID feature\n",
    "    X_train = X_train.drop('sig_id', axis=1)\n",
    "    X_test  = X_test.drop('sig_id', axis=1)\n",
    "    # Get indices for train and test dfs - we'll need these later\n",
    "    train_idx = list(X_train.index)\n",
    "    test_idx  = list(X_test.index)\n",
    "    # Separate train data types\n",
    "    X_train_numerical   = X_train.select_dtypes('number')\n",
    "    X_train_categorical = X_train.select_dtypes('object')\n",
    "    X_train_categorical = X_train_categorical.astype('category')\n",
    "    # Separate val data types\n",
    "    X_test_numerical   = X_test.select_dtypes('number')\n",
    "    X_test_categorical = X_test.select_dtypes('object')\n",
    "    X_test_categorical = X_test_categorical.astype('category')\n",
    "    \n",
    "    \n",
    "    ## SCALING ##\n",
    "    \n",
    "    if scaler is not None:\n",
    "        if verbose == 1:\n",
    "            print('APPLYING SCALER...')\n",
    "        # Fit and transform scaler to train and val\n",
    "        scaler.fit(X_train_numerical)\n",
    "        X_train_numerical = scaler.transform(X_train_numerical)\n",
    "        X_test_numerical  = scaler.transform(X_test_numerical)\n",
    "    \n",
    "    \n",
    "    ## FEATURE SELECTION ##\n",
    "    \n",
    "    # Feature selection is only ran on numerical data\n",
    "    if feature_selector is not None:\n",
    "        if verbose == 1:\n",
    "            print('APPLYING FEATURE SELECTOR...')\n",
    "        # Fit tree based classifier to select features\n",
    "        if verbose == 1: \n",
    "            num_cols = X_train_numerical.shape[1]\n",
    "        feature_selector  = SelectFromModel(estimator=feature_selector).fit(X_train_numerical, y_train)\n",
    "        X_train_numerical = feature_selector.transform(X_train_numerical)\n",
    "        X_test_numerical  = feature_selector.transform(X_test_numerical)\n",
    "        if verbose == 1: \n",
    "            print(f'{num_cols - X_train_numerical.shape[1]} features removed in feature selection.')\n",
    "            del num_cols\n",
    "\n",
    "    \n",
    "    ## PCA ##\n",
    "    \n",
    "    if pca is not None:\n",
    "        if verbose == 1:\n",
    "            print('APPLYING PCA...')\n",
    "        # Fit and transform pca to train and val\n",
    "        pca.fit(X_train_numerical)\n",
    "        X_train_numerical = pca.transform(X_train_numerical)\n",
    "        X_test_numerical  = pca.transform(X_test_numerical)\n",
    "        if verbose == 1:\n",
    "            print(f'NUMBER OF PRINCIPAL COMPONENTS: {pca.n_components_}')\n",
    "    # Convert numerical features into pandas dataframe\n",
    "    X_train_numerical = pd.DataFrame(X_train_numerical, index=train_idx).add_prefix('pca_')\n",
    "    X_test_numerical  = pd.DataFrame(X_test_numerical, index=test_idx).add_prefix('pca_')\n",
    "    \n",
    "    \n",
    "    ## CATEGORICAL FEATURESÂ ##\n",
    "    \n",
    "    # Get categorical and numerical column names\n",
    "    num_cols = X_train_numerical.columns\n",
    "    cat_cols = X_train_categorical.columns\n",
    "    # Encode categorical features\n",
    "    X_train_categorical = X_train_categorical.apply(lambda x: x.cat.codes)\n",
    "    X_test_categorical  = X_test_categorical.apply(lambda x: x.cat.codes)\n",
    "\n",
    "    \n",
    "    # Concatenate transformed categorical features with transformed numerical features  \n",
    "    X_train = pd.concat([X_train_categorical, X_train_numerical], axis=1)\n",
    "    X_test = pd.concat([X_test_categorical, X_test_numerical], axis=1)\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print(f'TRAIN SHAPE: \\t{X_train.shape}')\n",
    "        print(f'TEST SHAPE: \\t{X_test.shape}')\n",
    "    \n",
    "    return X_train, X_test, num_cols, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_features\n",
    "y_train = transform_target_data(train_targets_scored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.00 Test Predictions\n",
    "\n",
    "Because in the model train pipeline, we performed in-fold Bayesian hyperparameter searches for each model, it is expected that the model architecture will be slighlty different for each of the 10 folds. Consequently, we'll need to do a little manual analysis to prepare the test prediction pipeline before we start to make the predictions (as we won't be able to feed in the same dataset into each model - differing transformations will be required per model).\n",
    "\n",
    "In future, I'd like to automate this step. In order to do this, more work will need to be carried out on the train notebook, but due to time constraints and resource limits, we will have to move on for now without making those amendments. \n",
    "\n",
    "### 4.01 Prepare Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After manually inspecting, these are the parameters that will affect the model inputs\n",
    "model_parameters = pd.DataFrame([[0, 200, True, 14],\n",
    "                                 [1, 200, False,14],\n",
    "                                 [2, 200, True, 14],\n",
    "                                 [3, 200, True, 14],\n",
    "                                 [4, 200, True, 14],\n",
    "                                 [5, 200, False,14],\n",
    "                                 [6, 200, False,14],\n",
    "                                 [7, 200, True, 14],\n",
    "                                 [8, 200, False,14],\n",
    "                                 [9, 200, False,14],\n",
    "                                 [0, 200, False,140],\n",
    "                                 [1, 200, False,140],\n",
    "                                 [2, 200, False,140],\n",
    "                                 [3, 200, False,140],\n",
    "                                 [4, 200, False,140],\n",
    "                                 [5, 200, False,140],\n",
    "                                 [6, 200, False,140],\n",
    "                                 [7, 200, False,140],\n",
    "                                 [8, 200, False,140],\n",
    "                                 [9, 200, False,140],\n",
    "                                ], \n",
    "                                columns=['kfold','num_components','use_embedding','seed'])\n",
    "\n",
    "# Create an empty dataframe for zero label indicators to populate during test pipeline\n",
    "preds_zero_label = sample_submission[['sig_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_predictions(X_test, \n",
    "                          num_components, \n",
    "                          use_embedding, \n",
    "                          seed, \n",
    "                          kfold, \n",
    "                          X_train=X_train, \n",
    "                          y_train=y_train, \n",
    "                          model_name=MODEL_NAME,\n",
    "                          submission=preds_zero_label):\n",
    "    \"\"\"\n",
    "    Reads in X_test feature set, loads the model specified by model_path, and \n",
    "    applies transformations as per num_components and use_embedding\n",
    "    \n",
    "    Returns dataframe with sig_id and a binary column indicating \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the dataframe ids that were used in kfold during cross validation (using specified seed)\n",
    "    skf = StratifiedKFold(n_splits=KFOLDS, random_state=seed)\n",
    "    for fold, (tdx, vdx) in enumerate(skf.split(X_train, y_train)):\n",
    "        if fold == kfold:\n",
    "            # End the loop when it gets to kfold so we can retain tdx for kfold\n",
    "            break\n",
    "    \n",
    "    # Subset X_train and y_train as per what occurred during cross validation for kfold and seed\n",
    "    X_train, y_train = X_train.iloc[tdx, :], y_train.iloc[tdx, :]\n",
    "    \n",
    "    # Transform data - again to replicate what occurred with at kfold and seed\n",
    "    X_train, X_test, num_cols, cat_cols = transform_feature_set(X_train        = X_train, \n",
    "                                                                X_test         = X_test, \n",
    "                                                                y_train        = y_train, \n",
    "                                                                seed           = seed,\n",
    "                                                                num_components = num_components)\n",
    "    \n",
    "    # Further transformations if an embedding was used at kfold and seed\n",
    "    if use_embedding == True:\n",
    "        # Separate data to fit into embedding and numerical input layers\n",
    "        X_train = [np.absolute(X_train[i]) for i in cat_cols] + [X_train[num_cols]]\n",
    "        X_test = [np.absolute(X_test[i]) for i in cat_cols] + [X_test[num_cols]]\n",
    "        \n",
    "        \n",
    "    # Get the model name and file path for kfold and seed, then load that model\n",
    "    model_name = model_name + '_seed' + str(seed)\n",
    "    model_path = 'weights/' + model_name + '/' + model_name + '_' + str(kfold) + '.h5'\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Make test predictions using the model created at kfold and seed\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    # Add new column for kfold\n",
    "    submission['zero_label_' + 'fold_' + str(kfold) + '_seed_' + str(seed)] = preds\n",
    "        \n",
    "    return(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.02 Make Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make 0_label test predictions for all models created during CV for all seeds\n",
    "for idx in tqdm(model_parameters.index):\n",
    "    y_preds = make_test_predictions(\n",
    "        X_test         = test_features, \n",
    "        num_components = model_parameters.iloc[idx]['num_components'], \n",
    "        use_embedding  = model_parameters.iloc[idx]['use_embedding'], \n",
    "        seed           = model_parameters.iloc[idx]['seed'], \n",
    "        kfold          = model_parameters.iloc[idx]['kfold']\n",
    "    )\n",
    "\n",
    "y_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean for all predictions across folds and seeds\n",
    "y_preds['zero_label'] = y_preds.iloc[:, 1:].mean(axis=1)\n",
    "# Finalise zero_label prediction to just one column\n",
    "y_preds = y_preds[['sig_id', 'zero_label']]\n",
    "y_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.03 Create submission for zero label classifier\n",
    "In order to test the efficacy of our zero label classfier, we'll make a submission and compare it to the results of the sample submission.\n",
    "\n",
    "We'll have to invert the probabilities for the zero labels, and the multiply the sample submission values (0.5) by the prediction. We'll figure out where this zero label classifier belongs in the overall pipeline based on the difference in leaderboard scores between the transformed submission and the sample submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert probabilities \n",
    "y_preds['zero_label'] = 1 - y_preds['zero_label']\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in zero_label predictions\n",
    "sample_sub = sample_submission.merge(y_preds, on='sig_id')\n",
    "\n",
    "# Multiply all probabilities by inverted zero_label probabilities\n",
    "sample_sub.iloc[:, 1:-1] = sample_sub.iloc[:, 1:-1].multiply(sample_sub['zero_label'], axis=0)\n",
    "\n",
    "# If there is a high probability of a zero_label, replace all values with 0\n",
    "#for row in sample_sub.index:\n",
    "#    if (1 - sample_sub.iloc[row, -1].item()) >= 0.75:\n",
    "#        sample_sub.iloc[row, 1:-1] = 0\n",
    "\n",
    "\n",
    "# Remove zero_label column\n",
    "sample_sub.drop('zero_label', axis=1, inplace=True)\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub.to_csv('submissions/submission_zero_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
